version: '3.8'

services:
  # NGINX Reverse Proxy + SSL Termination
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/logs:/var/log/nginx
    depends_on:
      - spike-absorber
      - api
    restart: unless-stopped
    networks:
      - frontend
      - backend

  # Spike Absorber - Fast ACK Layer
  spike-absorber:
    build:
      context: ./workers
      dockerfile: Dockerfile.spike-absorber
    environment:
      NODE_ENV: production
      REDIS_URL: redis://redis:6379
      SUPABASE_URL: ${SUPABASE_URL}
      SUPABASE_KEY: ${SUPABASE_ANON_KEY}
      MAX_THROUGHPUT: 1000
      ACK_TIMEOUT_MS: 100
    ports:
      - "8080:8080"
    depends_on:
      - redis
    restart: unless-stopped
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 256M
    networks:
      - backend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Main API Server
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    environment:
      NODE_ENV: production
      PORT: 3000
      REDIS_URL: redis://redis:6379
      SUPABASE_URL: ${SUPABASE_URL}
      SUPABASE_SERVICE_KEY: ${SUPABASE_SERVICE_KEY}
      JWT_SECRET: ${JWT_SECRET}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
    ports:
      - "3000:3000"
    depends_on:
      - redis
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    networks:
      - backend
    volumes:
      - ./api/logs:/app/logs
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:3000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3

  # Worker A - Lightweight Tasks
  worker-a:
    build:
      context: ./workers
      dockerfile: Dockerfile.worker-a
    environment:
      NODE_ENV: production
      REDIS_URL: redis://redis:6379
      SUPABASE_URL: ${SUPABASE_URL}
      SUPABASE_SERVICE_KEY: ${SUPABASE_SERVICE_KEY}
      WORKER_TYPE: A
      MAX_CONCURRENT: 10
      THIN_MODE_ENABLED: "true"
    depends_on:
      - redis
    restart: unless-stopped
    deploy:
      replicas: 5
      resources:
        limits:
          cpus: '0.4'
          memory: 768M
        reservations:
          cpus: '0.2'
          memory: 512M
    networks:
      - backend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Worker B - AI Orchestration
  worker-b:
    build:
      context: ./workers
      dockerfile: Dockerfile.worker-b
    environment:
      NODE_ENV: production
      REDIS_URL: redis://redis:6379
      SUPABASE_URL: ${SUPABASE_URL}
      SUPABASE_SERVICE_KEY: ${SUPABASE_SERVICE_KEY}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      WORKER_TYPE: B
      MAX_CONCURRENT: 5
      AI_TIMEOUT_MS: 2000
      LOCAL_MODEL_FALLBACK: "true"
    depends_on:
      - redis
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    networks:
      - backend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Worker C - Medium Tasks
  worker-c:
    build:
      context: ./workers
      dockerfile: Dockerfile.worker-c
    environment:
      NODE_ENV: production
      REDIS_URL: redis://redis:6379
      SUPABASE_URL: ${SUPABASE_URL}
      SUPABASE_SERVICE_KEY: ${SUPABASE_SERVICE_KEY}
      WORKER_TYPE: C
      MAX_CONCURRENT: 8
    depends_on:
      - redis
    restart: unless-stopped
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    networks:
      - backend

  # Redis - Caching + Queue + Idempotency
  redis:
    image: redis:7-alpine
    command: >
      redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru --appendonly yes --appendfsync everysec
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    restart: unless-stopped
    networks:
      - backend
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 30s
      timeout: 10s
      retries: 3

  # Prometheus - Metrics
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./observability/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./observability/prometheus-rules.yaml:/etc/prometheus/rules.yaml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    restart: unless-stopped
    networks:
      - backend

  # Grafana - Dashboards
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_ROOT_URL: https://monitoring.yourdomain.com
    volumes:
      - ./observability/grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml:ro
      - ./observability/grafana-dashboard.json:/etc/grafana/provisioning/dashboards/dashboard.json:ro
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
    restart: unless-stopped
    networks:
      - backend

  # Node Exporter - Host Metrics
  node-exporter:
    image: prom/node-exporter:latest
    command:
      - '--path.rootfs=/host'
    volumes:
      - /:/host:ro,rslave
    restart: unless-stopped
    networks:
      - backend

  # Backup Service - Hetzner Object Storage
  backup:
    build:
      context: ./backup
      dockerfile: Dockerfile
    environment:
      S3_ENDPOINT: ${HETZNER_S3_ENDPOINT}
      S3_BUCKET: ${HETZNER_S3_BUCKET}
      S3_ACCESS_KEY: ${HETZNER_S3_ACCESS_KEY}
      S3_SECRET_KEY: ${HETZNER_S3_SECRET_KEY}
      BACKUP_SCHEDULE: "0 2 * * *" # Daily at 2 AM
      SUPABASE_URL: ${SUPABASE_URL}
      SUPABASE_SERVICE_KEY: ${SUPABASE_SERVICE_KEY}
    volumes:
      - ./backups:/backups
      - redis-data:/data/redis:ro
    restart: unless-stopped
    networks:
      - backend

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge

volumes:
  redis-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /mnt/HC_Volume_1/redis # Hetzner Block Storage
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
